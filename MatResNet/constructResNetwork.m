function net = constructResNetwork(inputSizes)

net.meta.inputSize = inputSizes;
channels = imputSizes(3);
nResUnits = 5;
layersInResUnit = 5;

net.layers = {} ;
prevResPtr = ptr('top');
nextResPtr = ptr();
net.layers{end + 1} = struct(...
    'name', sprintf('res %d',0),...
    'type', 'custom',...
    'forward',@resForward,...
    'backward',@resBackward,...
    'prevResPtr',prevResPtr ,...
    'nextResPtr', nextResPtr);
prevResPtr = nextResPtr;
nextResPtr = ptr();
for i = 1:n
    %TODO: Check how to propperly initialize bn layer
    net.layers{end + 1} = struct(...
        'name', sprintf('bn %d',i'),...
        'type', 'bnorm',...
        'weights',{ones(channels,1),ones(chanels,1)});
    
    net.layers(end + 1) = struct(...
        'name', sprintf('relu %d',i),...
        'type', 'relu');
    
    %TODO: Check parameters for conv
    net.layers{end + 1} = struct(...
      'name', spritf('conv %d',i), ...
      'type', 'conv', ...
      'weights', {xavier(3,3,1,32)}, ...
      'pad', 1, ...
      'stride', 1, ...
      'learningRate', [1 1], ...
      'weightDecay', [1 0]);
  
    net.layers{end + 1} = struct(...
        'name', sprintf('res %d',i),...
        'type', 'custom',...
        'forward',@resForward,...
        'backward',@resBackward,...
        'prevResPtr', prevResPtr,...
        'nextResPtr', nextResPtr);
    prevResPtr = nextResPtr;
    nextResPtr = ptr();
    
end
net.layers(end).nextResPtr.val = 'bottom';
net = vl_simplenn_tidy(net) ;
end

function res_ = resForward(layer,res, res_)
    if strcmp(layer.prevResPtr.val,'top')
        %Is first layer
        x = res.x;
    else
        x_bypass = layer.prevResPtr.val.x;
        x = x_bypass + res.x;
    end
    
    if ~strcmp(layer.prevResPtr.val,'bottom') 
        layer.nextResPtr.val.x = x;        
    end
    res_.x = x;
end

function res = resBackward(layer,res,res_)
    if 
    res.dzdx = layer.nextResPtr.val.dzdx + res_.dzdx;
    layer.prevResPtr.dzdx = res.dzdx;
end